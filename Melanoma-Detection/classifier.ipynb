{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 64\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(512),\n",
    "    transforms.CenterCrop(512),\n",
    "    transforms.RandomHorizontalFlip(), # randomly flip and rotate\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "tv_transform = transforms.Compose([\n",
    "    transforms.Resize(512),\n",
    "    transforms.CenterCrop(512),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "train_data = datasets.ImageFolder('data/train', transform=transform)\n",
    "valid_data = datasets.ImageFolder('data/valid', transform=tv_transform)\n",
    "test_data = datasets.ImageFolder('data/test', transform=tv_transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "\n",
    "loaders = [train_loader, valid_loader, test_loader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 16, 1)\n",
    "        self.conv2 = nn.Conv2d(16, 16, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.avgpool = nn.AvgPool2d(2,2)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.fc1 = nn.Linear(64 * 64 * 32, 512)\n",
    "        self.fc2 = nn.Linear(512,3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(-1, 64 * 64 * 32)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = F.log_softmax(self.fc2(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer = models.alexnet(pretrained=True)\n",
    "transfer.classifier[6] = nn.Linear(4096, 3)\n",
    "transfer.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(transfer.parameters(), lr=0.01)\n",
    "transfer.load_state_dict(torch.load('transfer.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "def train(n_epochs, loader, model, optimizer, criterion, use_cuda, save_path):\n",
    "    valid_loss_min = 1.077\n",
    "    train_loss = 0\n",
    "    valid_loss = 0\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(loader[0]):\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            if batch_idx == 0:\n",
    "                print('Started Batch')\n",
    "            optimizer.zero_grad()       \n",
    "            output = model(data)        \n",
    "            loss = criterion(output, target)        \n",
    "            loss.backward()        \n",
    "            optimizer.step() \n",
    "            torch.cuda.empty_cache() \n",
    "            train_loss += loss.item()*data.size(0)\n",
    "        model.eval()\n",
    "        for batch_idx, (data, target) in enumerate(loader[1]):\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            valid_loss += loss.item()*data.size(0)\n",
    "            torch.cuda.empty_cache()\n",
    "        train_loss = train_loss/len(loader[0].dataset)\n",
    "        valid_loss = valid_loss/len(loader[1].dataset)\n",
    "        \n",
    "        print('Epoch: {} \\tTraining Loss: {:.3f} \\tValidation Loss: {:.3f}'.format(\n",
    "            epoch, train_loss, valid_loss))\n",
    "        \n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.3f} --> {:.3f}).  Saving model ...'.format(\n",
    "            valid_loss_min,\n",
    "            valid_loss))\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            valid_loss_min = valid_loss\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Batch\n",
      "Epoch: 1 \tTraining Loss: 0.834 \tValidation Loss: 1.105\n",
      "Started Batch\n",
      "Epoch: 2 \tTraining Loss: 0.835 \tValidation Loss: 1.117\n",
      "Started Batch\n",
      "Epoch: 3 \tTraining Loss: 0.835 \tValidation Loss: 1.113\n",
      "Started Batch\n",
      "Epoch: 4 \tTraining Loss: 0.835 \tValidation Loss: 1.118\n",
      "Started Batch\n",
      "Epoch: 5 \tTraining Loss: 0.835 \tValidation Loss: 1.116\n",
      "Started Batch\n",
      "Epoch: 6 \tTraining Loss: 0.835 \tValidation Loss: 1.115\n",
      "Started Batch\n",
      "Epoch: 7 \tTraining Loss: 0.835 \tValidation Loss: 1.120\n",
      "Started Batch\n",
      "Epoch: 8 \tTraining Loss: 0.835 \tValidation Loss: 1.114\n",
      "Started Batch\n",
      "Epoch: 9 \tTraining Loss: 0.835 \tValidation Loss: 1.117\n",
      "Started Batch\n",
      "Epoch: 10 \tTraining Loss: 0.835 \tValidation Loss: 1.117\n",
      "Started Batch\n",
      "Epoch: 11 \tTraining Loss: 0.835 \tValidation Loss: 1.117\n",
      "Started Batch\n",
      "Epoch: 12 \tTraining Loss: 0.835 \tValidation Loss: 1.117\n",
      "Started Batch\n",
      "Epoch: 13 \tTraining Loss: 0.835 \tValidation Loss: 1.116\n",
      "Started Batch\n",
      "Epoch: 14 \tTraining Loss: 0.835 \tValidation Loss: 1.117\n",
      "Started Batch\n",
      "Epoch: 15 \tTraining Loss: 0.835 \tValidation Loss: 1.117\n",
      "Started Batch\n",
      "Epoch: 16 \tTraining Loss: 0.835 \tValidation Loss: 1.116\n",
      "Started Batch\n",
      "Epoch: 17 \tTraining Loss: 0.835 \tValidation Loss: 1.115\n",
      "Started Batch\n",
      "Epoch: 18 \tTraining Loss: 0.835 \tValidation Loss: 1.119\n",
      "Started Batch\n",
      "Epoch: 19 \tTraining Loss: 0.835 \tValidation Loss: 1.110\n",
      "Started Batch\n"
     ]
    }
   ],
   "source": [
    "train(200, loaders, transfer, optimizer, criterion, True, 'transfer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loaders, model, criterion, use_cuda):\n",
    "\n",
    "    # monitor test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "        \n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(loaders[2]):\n",
    "        # move to GPU\n",
    "        print(batch_idx)\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average test loss \n",
    "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "        # convert output probabilities to predicted class\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        # compare predictions to true label\n",
    "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "        total += data.size(0)\n",
    "            \n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
    "        100. * correct / total, correct, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(loaders, model, criterion, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "class_names = [item[4:].replace(\"_\", \" \") for item in train_data.classes]\n",
    "\n",
    "def softmax(one, two, three):\n",
    "    return np.exp(one)/(np.exp(one)+np.exp(two)+np.exp(three))\n",
    "   \n",
    "def display_image(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    cv_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(cv_rgb)\n",
    "    plt.show()\n",
    "\n",
    "def detect(img_path):\n",
    "    # load the image and return the predicted breed\n",
    "    display_image(img_path)\n",
    "    image = Image.open(img_path).convert('RGB')\n",
    "    in_transform = transforms.Compose([\n",
    "                        transforms.Resize(256),\n",
    "                        transforms.CenterCrop(224),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])])\n",
    "                        \n",
    "    \n",
    "    image = in_transform(image)[:3,:,:].unsqueeze(0)\n",
    "    image= image.cuda()\n",
    "    output = model(image)\n",
    "    index = torch.topk(output,3)\n",
    "    one = index[0][0][0].item()\n",
    "    two = index[0][0][1].item()\n",
    "    three = index[0][0][2].item()\n",
    "    \n",
    "    return(str(softmax(one,two,three)*100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('model.pth'))\n",
    "print(detect('data/test/seborrheic_keratosis/ISIC_0012136.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
